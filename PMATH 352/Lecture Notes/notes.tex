\documentclass[11pt]{article}
\usepackage{notes}

\newcommand{\thiscoursecode}{PMATH 348}
\newcommand{\thiscoursename}{Complex Analysis}
\newcommand{\thisprof}{Prof. Akshaa Vatwani}
\newcommand{\me}{Kevin Cheng}
\newcommand{\thisterm}{Winter 2018}

\newcommand{\Arg}{\text{Arg}}
\newcommand*{\pd}[3][]{\ensuremath{\frac{\partial^{#1} #2}{\partial #3^{#1}}}}

\hypersetup
{pdfauthor={\me},
pdftitle={\thiscoursecode \thisterm Lecutre Notes},
pdfsubject={\thiscoursename}
pdflang={English}}

\begin{document}
\begin{titlepage}
\begin{centering}
{\scshape\LARGE University of Waterloo \par}
\globe
{\huge\bf \thiscoursecode}\\
{\scshape\Large \thiscoursename}\\
\vspace{.3cm}
{\scshape \thisprof~\textbullet~\thisterm \par}
\end{centering}
\sectionline
\tableofcontents
\sectionline
\thispagestyle{empty}
\end{titlepage}

\section{Complex Numbers}
\begin{definition}
A \underline{complex number} is a vector in $\R^2$. The \underline{complex plane} denoted by $\C$ is the
set of complex numbers. 
\begin{equation*}
\C = \R^2 = \bigg\{\begin{pmatrix}x\\y\end{pmatrix}: x, y \in \R \bigg\}
\end{equation*}
In $\C$, we usually write,
\begin{align*} 
0 &= \begin{pmatrix}0\\0\end{pmatrix}\\
1 &= \begin{pmatrix}1\\0\end{pmatrix}\\
i &= \begin{pmatrix}0\\1\end{pmatrix}\\
x &= \begin{pmatrix}x\\0\end{pmatrix}\\
iy &= \begin{pmatrix}0\\y\end{pmatrix}
\end{align*}
with $x, y \in \R$. If $z = x + iy, x, y \in \R$, then $x$ is called the real
part of $z$ and $y$ the imaginary part of $z$ and write
\begin{equation*}
\Re(z) = x \qquad \Im(z) = y
\end{equation*}
\end{definition}
\begin{definition}
We define the \underline{sum of two complex numbers} to be the vector sum.
\begin{align*}
(a+ib)+(c + id) &=
\begin{pmatrix}a \\ b\end{pmatrix} + 
\begin{pmatrix}c \\ d\end{pmatrix}\\
&= 
\begin{pmatrix}a + c \\ b + d\end{pmatrix} 
\end{align*}
We define the \underline{product of two complex numbers} by setting $i^2 = -1$ and by
requiring the product to be commutative, associative and distributive over the
sum.
So,
\begin{align*}
(a + bi)(c + di) &=
ac + iad + ibc + i^2bd\\
&= (ac - bd) + (ad + bc)
\end{align*}
\end{definition}
\begin{prop}[Mulitplicative Inverses]
Every complex number has a unique multiplicative inverse denoted by
$z^{-1}$.
\end{prop}
\begin{proof}
Let $z = a + i, a,b \in \R$ with $a^2 + b^2 = 0$. We want to solve for $x$ and
$y$ such that $(a + ib)(x + iy) = 1$. In other words,
\begin{align*}
&\> (ax - by) + i(ay + bx) = 1\\
\Rightarrow &\>
\begin{pmatrix}
ax - by \\ bx + ay
\end{pmatrix}
= (1,0)\\
\Rightarrow &\>
\begin{pmatrix}
a & -b\\
b & a
\end{pmatrix}
\begin{pmatrix}
x \\ y
\end{pmatrix}
= (1,0)\\
\Rightarrow &\>
\begin{pmatrix}
x \\ y
\end{pmatrix}
=
\begin{pmatrix}
a & -b\\
b & a
\end{pmatrix}^{-1}
\begin{pmatrix}
1 \\ 0
\end{pmatrix}\\
\Rightarrow &\>
\begin{pmatrix}
x \\ y
\end{pmatrix}
=
\frac{1}{a^2 + b^2}
\begin{pmatrix}
a & b\\
-b & a
\end{pmatrix}
\begin{pmatrix}
1 \\ 0
\end{pmatrix}\\
\Rightarrow &\>
\begin{pmatrix}
x \\ y
\end{pmatrix}
=
\begin{pmatrix}
\frac{a}{a^2 + b^2} \\ \frac{b}{a^2 + b^2}
\end{pmatrix}
\end{align*}
This is unique as the inverse matrix is unique.
\end{proof}
\begin{remark}
The set of complex numbers is a \underline{field} under the operations of
addition and multiplication as operations are associative, commutative
and distributive and every element has a unique inverse as before.
\end{remark}
\begin{definition}
If $z = x + iy, x, y, \in \R$, then the \underline{conjugate of $z$} is
$\bar{z} = x - iy$.
\end{definition}
\begin{definition}
We define the \underline{modulus} (or length or magnitude) of $z = x + iy, x, y \in \R$ to
be
\begin{equation*}
|z| = \sqrt{x^2 + y^2} \in \R
\end{equation*}
\end{definition}
\begin{remark}
For any $z, w \in \C$,
\begin{align*}
\bar{\bar{z}} &= z\\
z + \bar{z} &= 2\Re(z)\\
z - \bar{z} &= 2\Im(z)\\
z\cdot\bar{z} &= |z|^2\\
|z| &= |\bar{z}|\\
\bar{z+w} &= \bar z + \bar w\\
\bar{zw} &= \bar z\cdot\bar w\\
|zw| &= |z||w|
\end{align*}
\end{remark}
\begin{prop}
The following inequalities hold for any $z \in \C$.
\begin{enumerate}
\item $|\Re(z)| \leq |z|$
\item $|\Im(z)| \leq |z|$
\item $|z + w| \leq |z| + |w|$
\item $|z + w| \geq \bigg| |z| - |w|\bigg|$
\end{enumerate}
\begin{proof}
(1) and (2) follows as
\begin{equation*}
|z|^2 = \Re(z)^2 + \Im(z)^2. 
\end{equation*}
(3). Notice,
\begin{align*}
|x + iy|^2 &= (x + iy)\bar{(x + iy)}\\
&= (x + iy)(\bar{x} + \bar{iy})\\
&= x\bar x + y \bar y + x \bar y + y \bar x\\
&= |x|^2 + |y|^2 + x \bar y + y \bar x\\
&= |x|^2 + |y|^2 + 2\Re(x\bar y)\\
&\leq |x|^2 + |y|^2 + 2|x\bar y|\\
&= |x|^2 + |y|^2 + 2|x| \cdot |\bar y|\\
&= |x + y|^2
\end{align*}
Taking the square root of both sides gives the result.\\

(4). From (3), we have that
\begin{align*}
|z| = |z - w + w| &\leq |z - w| + |w|\\ 
|w| = |w - z + z| &\leq |w - z| + |z|
\end{align*}
Then, isolating $|z - w|$ implies the result. More specifically since we have the simulateous inequality,
\begin{equation*}
\begin{cases}
|z| - |w| \leq |z - w| \\
|w| - |z| \leq |z - w|
\end{cases}
\Rightarrow
|z - w| \geq \bigg| |z| - |w| \bigg|
\end{equation*}
as desired.
\end{proof}
\end{prop}
\begin{prop}
Every non-zero complex number has exactly 2 square roots.
\end{prop}
\begin{proof}
Let $z = x + iy \in \C$ with $x^2 + y^2 \neq 0, x, y, \in \R$. We want to solve
$w^2 = z$ for $w \in \C$. Say $w$ takes the form $w = u + iv, u, v \in \R$. Then
\begin{align*}
& \> w^2 = z\\
\Rightarrow & \> (u+iv)^2 = x + iy\\
\Rightarrow & \> (u^2 - v^2) + i2uv = x + iy
\end{align*}
So we have that $x = u^2 - v^2$ and $y = 2uv^2$. We can solve for $u$ and $v$.
Take the square of both sides of the second equation to get $4u^2v^2 = y^2$.
Now, we multiply the first equation by $4u^2$ to get
\begin{align*}
& \> 4u^4 - 4u^2v^2 = 4xu^2\\
\Rightarrow & \> 4u^4 - 4xu^2 - y^2 = 0
\end{align*}
This is a quadratic equation over $u^2$ so,
\begin{equation*}
u^2 = \frac{4x \pm \sqrt{16x^2 + 16y^2}}{8} = \frac{x \pm \sqrt{x^2 + y^2}}{2}
\end{equation*}
Suppose that $y \neq 0$. Then we must take the positive solution above to get
\begin{equation*}
u^2 = \frac{x + \sqrt{x^2 + y^2}}{2}
\end{equation*}
Under the assumption that $x^2 + y^2 > 0$, this solution exists. Notice we
cannot take the negative solution as it yields a negative $u^2$ which is
impossible. We can use a similar procedure to find that
\begin{equation*}
v^2 = \frac{-x + \sqrt{x^2 + y^2}}{2}
\end{equation*}
Rooting $u$ and $v$ gives 2 solutions for each. However, if $y$ is positive,
since $2uv = y$, $u$ and $v$ must take the same sign. Similarly, if $y$ is
negative, they must take different signs. In each of these cases, there are 2
solutions for $u$ and $v$. So,
\begin{equation*}
w = 
\begin{cases}
\pm \Bigg[ \bigg(\sqrt{\frac{x + \sqrt{x^2 + y^2}}{2}}\bigg) +
i\bigg(\sqrt{\frac{-x + \sqrt{x^2 + y^2}}{2}}\bigg)\Bigg] &, \> y > 0\\
\pm \Bigg[ \bigg(\sqrt{\frac{x + \sqrt{x^2 + y^2}}{2}}\bigg) -
i\bigg(\sqrt{\frac{-x + \sqrt{x^2 + y^2}}{2}}\bigg)\Bigg] &, \> y < 0\\
\pm \sqrt x &, \> x > 0,\> y = 0\\
\pm i\sqrt -x &, \> x < 0,\> y = 0
\end{cases}
\end{equation*}
\end{proof}
\begin{remark}
Let $z \in \C$. The notation $\sqrt z$ may represent either one of the square
roots of $z$ or both of the square roots.
\end{remark}
\begin{remark}
The square root doesn't distribute. Consider $z = w = -1 \in \C$.
$\sqrt{zw} \neq \sqrt z \sqrt w$.
\end{remark}
\begin{remark}
The Quadratic Formula holds true for complex polynomials. In other words, if $a,
b, c \in \C, a \neq 0$,
\begin{equation*}
az^2 + bz + c = 0 \Rightarrow z = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}
\end{equation*}
\end{remark}
\begin{definition}
If $z \in \C \setminus \{0\}$, we define the \underline{angle} (or
\underline{argument}) of $z$ to be the angle $\theta(z)$ from the positive
$x$-axis counterclockwise to $z$. In other words, $\theta(z)$ is the angle such
that
\begin{equation*}
z = |z|\big(\cos\theta(z) + i\sin\theta(z)\big).
\end{equation*}
\end{definition}
\begin{remark}
For $\theta \in \R$ (or for $\theta \in \R/2\pi$), we have that
\begin{equation*}
e^{i\theta} = \cos(\theta) + i\sin(\theta)
\end{equation*}
\end{remark}
\begin{remark}
If $z \neq 0$, we have $x = \Re(z)$, $y = \Im(z)$, $r = |z|$ and
\begin{align*}
x &= r\cos\theta\\
y &= r\sin\theta\\
\tan\theta &= \frac{y}{x},\>\text{if } x \neq 0\\
z &= re{i\theta}\\
\bar z &= re^{-i\theta}\\
z^{-1} &= \frac{1}{r}e^{-i\theta} 
\end{align*}
\end{remark}
\begin{remark}
We now have 2 representations of a complex number $z\in\C$. We say that
$z = x + iy$ is the \underline{cartesian coordinates} of $z$ and $z =
re^{i\theta}$, where $r = |z|$, is the \underline{polar form} of $z$.
\end{remark}
Consider $z = re^{i\alpha}$ and $w = se^{i\beta}$. We have,
\begin{align*}
zw &= rs(\cos\alpha + i\sin\alpha)(\sin\beta + i\cos\beta)\\
&= rs\big((\cos\alpha\cos\beta-\sin\alpha \sin\beta) +
i(\sin\alpha\cos\beta+\cos\alpha\sin\beta)\big)\\
&= rs\big(\cos(\alpha + \beta) + i\sin(\alpha + \beta)\big)\\
&= e^{i(\alpha + \beta)}
\end{align*}
which defines a formula for multiplication in polar coordinates. Notice that the
following identity known as De Moivre's Law follows.
\begin{equation*}
(re^{i\theta})^n = r^ne^{in\theta}
\end{equation*}
for all $r,\theta \in \R$, $n \in \Z$. We can use this identity to find the
$n^\text{th}$ roots of $z$. In other words, we solve $w^n = z$. We have,
\begin{align*}
&\> w^n = z\\
\Rightarrow & \> (se^{i\alpha})^n = re^{i\theta}\\
\Rightarrow & \> s^ne^{in\alpha} = re^{i\theta}
\end{align*}
so $s^n = r$ and $n\alpha = \theta + 2\pi k$ for $k \in \Z$. In other words, we
have
\begin{equation*}
(re^{i\theta}) = \sqrt[n]r e^{i(\theta + 2\pi k )/n}, \quad k = 0,\dots,n-1
\end{equation*}
\begin{remark}
When working with complex numbers, for $0 \neq z \in \C$, and for $0 < n \in
\Z$, $\sqrt[n]z$ or $z^{1/n}$ denotes either one of the $n$ roots, or the set of
all $n^{\text{th}}$ roots.
\end{remark}
\begin{example}
Consider the $n-1$ diagonals of a regular $n$-gon inscribed in a circle of
radius 1 obtained by connecting one vector with all the others. Show that the
product of these diagonals is $n$.
\end{example}
Notice that $z_2,\dots,z_n$ are the $n^{\text{th}}$ roots of unity other than 1.
Let $z$ be the variable and consider the polynomial
\begin{equation*}
P(z) \coloneqq 1 + z + \dots + z^{n-1}.
\end{equation*}
Since the roots of $P(z)$ are $n^{\text{th}}$ roots of unity other than 1, we
can factorize
\begin{align*}
P(z) &= 1 + z + \dots + z^{n-1}\\
&= (z - z_2)\dots(z-z_n)
\end{align*}
and setting $z = 1$, the result follows. In particular, we have
\begin{equation*}
|1 - z_2|\dots|1 - z_n| = n.
\end{equation*}

\section{Complex Functions}
\subsection{Limits}
\begin{definition}
A sequence of complex numbers $z_1, z_2 \dots$ converges to $z \in C$ if
\begin{equation*}
\lim_{n \to \infty} |z_n - z| = 0.
\end{equation*}
Equivalently, given any $\epsilon > 0$, $\exists N_\epsilon \in \N$ sufficiently
large such that $|z_n - z| < \epsilon$ whenever $n>N$.
\end{definition}
\begin{remark}
If $\{z_n\}_n$ converges to $z$, we write
\begin{equation*}
\lim_{n \to \infty} z_n = z
\end{equation*}
or $z_n \to z$ as $n \to \infty$.
\end{remark}
\begin{example}
For $|z| > 1$, show that $\{\frac{1}{z^n}\}^{\infty}_{n=1}$ converges.
\end{example}
Notice,
\begin{equation*}
\lim_{n \to \infty} \bigg|\frac{1}{z^n} - 0\bigg|
= \lim_{n \to \infty} \bigg|\frac{1}{z^n}\bigg|
= 0
\end{equation*}
as $|z| > 1$.
\begin{example}
Show that $\{i^n\}^\infty_{n-1}$ does not converge.
\end{example}
\begin{definition}
Let $f:\Omega \subseteq \C \to \C$. We say
\begin{equation*}
\lim_{z \to z_0} f(z) = L
\end{equation*}
if for every sequence $\{z_n\}_n \subseteq \Omega$ we have that $z_n \to z
\Rightarrow f(z_n) \to L$.
\end{definition}
\begin{remark}
Here, $z_0$ need not to be in $\Omega$.
\end{remark}
\begin{example} \label{lim}
Let $f(z) = \frac{\bar z}{z}, z \in \C \setminus \{0\}$. Find $\lim_z \to 0
f(z)$.
\end{example}
If $z = x \in \R \setminus \{0\}$, then $f(z) = \frac{x}{x} = 1$. So
$\lim_{x \to 0} f(x) = 1$. If $z = iy, y \in \R \setminus \{0\}$, then $f(z) =
\frac{-iy}{iy} = -1$. So $\lim_{y \to 0} f(iy) = -1$. Hence, the limit does not
exist.
\begin{example}
Show that $z_n \to z$ if and only if $\Re z_n \to \Re z$ and $\Im z_n \to z$.
\end{example}

\subsection{Function Continuity}
\begin{definition}
Let $f:\Omega \subseteq \C \to \C $. We say $f$ is \underline{continuous at
$z_0 \in \Omega$} if for every sequence $\{z_n\} \subseteq \Omega$, we have $z_0 \to z
\Rightarrow f(z_0) \to f(z)$. Equivalently, given any $\epsilon > 0, \exists
\delta > 0$ such that $|f(z) - f(z_0)| < \epsilon$ whenever $|z - z_0| <
\delta$.
\end{definition}
\begin{remark}
$f$ is continuous on $\Omega$ if it is continuous at ever point of $\Omega$. 
\end{remark}
\begin{remark}
We may split $f$ into its real and imaginary parts
\begin{equation*}
f(z) = f(x,y) = u(x,y) + iv(x,y)
\end{equation*}
where $u,v : \R^2 \to \R$.
\end{remark}

\subsection{Holomorphic Functions}
\begin{definition}
An open disk of radius $r$ at $z_0$ with $r>0$ is the \underline{neighborhood}
around $z_0$ denoted by $D(z_0, r)$ with
\begin{equation*}
D(z_0, r) \coloneqq \{z\in\C:|z-z_0|<r\}
\end{equation*}
\end{definition}
\begin{definition}
Let $f(z)$ be defined in a neighborhood of $z_0$. We say $f$ is
\underline{complex differentiable} (or holomorphic) at $z_0$ if
\begin{equation*}
\lim_{h\to 0} \frac{f(z_0+h) - f(z_0)}{h}
\end{equation*}
exists. If it does, we denote the limit by $f'(z_0)$.
\end{definition}
\begin{remark}
Here, $h\in\C$ can approach zero from any direction in $\C$.
\end{remark}
\begin{example}
Where is $f(z) = \frac{1}{z}, z \neq 0$ holomorphic?
\end{example}
Notice,
\begin{equation*}
\lim_{h\to 0} \frac{\frac{1}{z_0+h} - \frac{1}{z_0}}{h}
= \lim_{h\to 0} \frac{-h}{(z_0+h)(z_0)}
= -\frac{1}{z_0^2}
\end{equation*}
So, $f$ is holomorphic at any $z \in \C \setminus \{0\}$, and $f'(z) =
-\frac{1}{z_0^2}$.
\begin{example}
$f(z) = \bar z$ is not holomorphic at any $z \in \C$.
\end{example}
Notice,
\begin{equation*}
\lim_{h\to 0} \frac{\bar{z_0 + h} - \bar{z_0}}{h}
= \lim_{h \to 0} \frac{\bar h}{h}
\end{equation*}
which does not exist from \cref{lim}. However, the function can be though of a
map from $\R^2 \to \R^2$ defined as $(x,y) \mapsto (x,-y)$ which is
differentiable as all partial derivatives exist. This distinguishes real
analysis from complex analysis.
\begin{remark}
If $f$ and $g$ are holomorphic, so are $f+g$, $fg$ and $\frac{f}{g}$ (when
$g\neq 0$). The proof is identical to the statements of real functions.
\end{remark}
\sectionline
We can now generalize when a function is complex differentiable. If the complex
function $f(z) = u + iv$. If the complex derivative $f'(z)$ is to exist, then it
must be that the limit exists approaching from both the real and imaginary
axis. Thus, we have,
\begin{equation*}
f'(z)  = \lim_{t\to 0} \frac{f(z+t) - f(z)}{t} = \lim_{t\to 0} \frac{f(z+it) -
f(z)}{it}
\end{equation*}
where $t$ is a real number. In terms of $u$ and $v$, taking the derivative along
the real line gives,
\begin{align*}
&\>\lim_{t\to 0} \frac{f(z+t) - f(z)}{t}\\
=&\> \lim_{t\to 0} \frac{u(x+t,y) + iv(x+t,y) - u(x,y) - iv(x,y)}{t}\\
=&\> \lim_{t\to 0} \frac{u(x+t,y) - u(x,y)}{t} + i\lim_{t\to 0} \frac{v(x+t,y) - 
v(x,y)}{t}\\
=&\> \pd{u}{x} + i \pd{v}{x}.
\end{align*}
Taking the derivative along the vertical line gives,
\begin{align*}
&\>\lim_{t\to 0} \frac{f(z+it) - f(z)}{it}\\
=&\> -i\lim_{t\to 0} \frac{u(x,y+t) + iv(x,y+t) - u(x,y) - iv(x,y)}{t}\\
=&\> -i\lim_{t\to 0} \frac{u(x,y+t) - u(x,y)}{t} + \lim_{t\to 0} \frac{v(x,y+t) - 
v(x,y)}{t}\\
=&\> -i\pd{u}{y} + \pd{v}{y}.
\end{align*}
Equating real and imaginary parts, we arrive at the following theorem.
\begin{theorem}[Cauchy-Riemann Equations] \label{theorem1}
If a function $f(z) = u + iv$ is holomorphic in a neighborhood around $z_0 = x_0
+ iy_0$, then the partial derivatives of $u$ and $v$ exist at $(x_0,y_0)$ and satisfy
\begin{equation*}
\pd{u}{x} = \pd{v}{y} \quad \text{and} \quad \pd{v}{x} = - \pd{u}{y}\quad\text{at }
(x_0,y_0)
\end{equation*}
with
\begin{equation*}
f'(z_0) = \pd{u}{x} + i \pd{v}{x} = \pd{v}{y} - i\pd{u}{y}.
\end{equation*}
\end{theorem}
\begin{example}
Show that
\begin{equation*}
f(z) =
\begin{cases}
\frac{\bar z^2}{z} & \text{, if } z \neq 0\\
0 & \text{, if } z = 0
\end{cases}
\end{equation*}
is not holomorphic at $z = 0$ and that the Cauchy-Reimann Equations hold at
$z = 0$.
\end{example}
Notice,
\begin{equation*}
\lim_{h \to 0} \frac{f(0+h) - f(0)}{h}
= \lim_{h \to 0} \frac{\bar h^2}{h^2}
= \lim_{h \to 0} \bigg(\frac{\bar x-iy}{x+iy}\bigg)^2
\end{equation*}
Let $h = x + imx$, $m \neq 0, x \to 0$. We get
\begin{equation*}
\lim_{x \to 0} \bigg( \frac{x - imx}{x + imx}\bigg)^2
\bigg( \frac{1 - im}{1 + im}\bigg)^2
\end{equation*}
which is dependent of $m$ and thus the limit does not exist. Now, notice we have
\begin{equation*}
\frac{\bar z^2}{z} = \frac{(x - iy)^2}{x+iy} = \frac{(x-iy)^3}{x^2+y^2}
= \frac{x^3 - 3xy^2}{x^2+y^2} + i \frac{-3x^2y + y^3}{x^2+y^2}
\end{equation*}
So we have
\begin{equation*}
u(x,y) =
\begin{cases}
\frac{x^3 - 3xy^2}{x^2+y^2} & \text{, if } (x,y) \neq (0,0)\\
0 & \text{, if } (x,y) = (0,0)
\end{cases}
\end{equation*}
and
\begin{equation*}
v(x,y) = 
\begin{cases}
\frac{-3x^2y + y^3}{x^2+y^2} & \text{, if } (x,y) \neq (0,0)\\
0 & \text{, if } (x,y) = (0,0)
\end{cases}.
\end{equation*}
Now, we can verify that the Cauchy-Riemann Equations hold. Indeed,
\begin{align*}
\pd{u}{x}\bigg(\frac{x^3 - 3xy^2}{x^2+y^2}\bigg)
&= \frac{\big(\pd{}{x}(x^3 - 3xy^2)\big)(x^2 + y^2) - (x^3 -
3xy^2)\big(\pd{}{x}(x^2+y^2)\big)}{(x^2 + y^2)^2}\\
&= \frac{(3x^2 - 3y^2)(x^2 + y^2) - (x^3 - 3xy^2)(2x)}{(x^2 + y^2)^2}\\
&= \frac{x^4 + 6x^2y^2 - 3y^4}{(x^2 + y^2)^2}\\
\pd{v}{y}\bigg(\frac{y^3 - 3x^2y}{x^2+y^2} \bigg)
&= \frac{\big(\pd{}{y}(y^3 - 3x^2y)\big)(x^2 + y^2) - (y^3 -
3x^2y)\big(\pd{}{y}(x^2+y^2)\big)}{(x^2 + y^2)^2}\\
&= \frac{(3y^2 - 3x^2)(x^2 + y^2) - (y^3 - 3x^2y)(y^2)}{(x^2 + y^2)^2}\\
&= \frac{x^4 + 6x^2y^2 - 3y^4}{(x^2 + y^2)^2}
\end{align*}
and
\begin{align*}
\pd{u}{y}\bigg(\frac{x^3 - 3xy^2}{x^2+y^2}\bigg)
&= \frac{\big(\pd{}{y}(x^3 - 3xy^2)\big)(x^2 + y^2) - (x^3 -
3xy^2)\big(\pd{}{y}(x^2+y^2)\big)}{(x^2 + y^2)^2}\\
&= \frac{(-6xy)(x^2 + y^2) - (x^3 - 3xy^2)(2y)}{(x^2 + y^2)^2}\\
&= -\frac{8x^3y}{x^2 + y^2}\\
\pd{v}{x}\bigg(\frac{y^3 - 3x^2y}{x^2+y^2} \bigg)
&= \frac{\big(\pd{}{x}(y^3 - 3x^2y)\big)(x^2 + y^2) - (y^3 -
3x^2y)\big(\pd{}{x}(x^2+y^2)\big)}{(x^2 + y^2)^2}\\
&= \frac{(-6xy)(x^2 + y^2) - (y^3 - 3x^2y)(2y)}{(x^2 + y^2)^2}\\
&= -\frac{8x^3y}{x^2 + y^2}
\end{align*}

Thus, we can consider the converse statement of \cref{theorem1}.
\begin{theorem}
Let $f=u+iv : \Omega \subseteq \C \to \C$, $z_0 = x_0 + iy_0 \in \Omega$. If
\begin{enumerate}
\item the partials of $u,v$ exist in a neighborhood of $(x_0,y_0)$
\item the partials of $u,v$ are continuous at $(x_0,y_0)$
\item $\pd{u}{x} = \pd{v}{y}$ and $\pd{v}{x} = - \pd{u}{y}$ at $(x_0,y_0)$
\end{enumerate}
then, $f$ is holomorphic at $z_0$.
\label{theorem2}
\end{theorem}
TODO: find proof online.

\begin{example}
Consider the \underline{power series}, an expression of the form
\begin{equation*}
\sum^\infty_{n=0} c_nz^n
\end{equation*}
where $c_n \in \C$. This expression \underline{converges} if the sequence of
partials sums, $\{s_N\}$ defined by
\begin{equation*}
s_N \coloneqq \sum^N_{n=0} c_nz^n 
\end{equation*}
converges as $N \to \infty$. This is quite a strong condition, so we consider
the following definition.
\end{example}
\begin{definition}
A power series expression \underline{converges absolutely} if
\begin{equation*}
\sum^{\infty}_{n=0} |c_n||z|^n
\end{equation*}
converges.
\end{definition}
\begin{remark}
Absolute convergence implies converges. Notice,
\begin{equation*}
\bigg| \sum_{n=0}^N c_n z^n \bigg| = \sum^N_{n=0} |c_n||z|^n
\end{equation*}
for each $N \in \N$.
\end{remark}
\end{document}
